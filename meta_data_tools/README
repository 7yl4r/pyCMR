The purpose of these tools is to make metadata generation for granules easier and more efficient.

The flow of control for metadata generation starts in a newly created python file just for that dataset.
Ideally this file is as short as possible because it just sets up variables for this dataset and calls the
funtion to print the metadata.  For an example, see iphex_hiwrap_metadata.py.

This dataset.py sets the root directory of the data, the top level directories in which to limit the search,
which parsers to use with which file patterns (more on that below), and common metadata entries in all records.
After all these are set, it calls print_metadata with this information.

print_metadata handles finding all the files, calling the parsers in separate threads to increase performance,
and printing out the metadata.  It will handle the metadata extraction for checksums, file sizes, file names,
and path names.

To get time and bounding box metadata, print_metadata calls parse functions based on what pattern matched the file.
The first three parse functions are read_uf, read_variable_nc, and read_constant_nc.  Read_uf is the example
on how to maximize efficiency, because it is capable of getting the metadata off of a stream that is passed in
as a file descriptor.  This file descriptor is fed from the print_metadata function that already has the file
open and is generating the checksum.  The file only has to be read once to generate all the metadata.

Read_variable_nc and read_constant_nc are for reading netCDF files.  The difference is that some netCDF files have
the time, lat, lon in variables.  Others have them in constants.

NetCDF files are read with ncdump, which will not work with a stream.  An actual filename is required.  So these
parse functions are not as efficient.  They are, however, run in parallel with the print_metadata doing the
checksumming.  Because of filesystem caching, this is more efficient than doing a checksum and then doing an ncdump.

NetCDF files have varying names for time, latitude, and longitude.  So these parse functions need some information
about the actual strings used for these variable names.  This information is entered in the dataset.py file as the
parser function arguments.  In the example iphex_hiwrap_metadata.py:

patternsToParsers = (
                      ("*.nc" , (read_variable_nc, "timed", "lat", "lon")),
                      ("*.h5" , (read_variable_nc, "timeUTC", "lat", "lon")),
                    )

This says in this dataset the .nc files use the words "timed", "lat", "lon", and the .h5 files use "timeUTC", "lat", "lon".

For more information, see dataset_HOWTO and run pydoc print_metadata.
